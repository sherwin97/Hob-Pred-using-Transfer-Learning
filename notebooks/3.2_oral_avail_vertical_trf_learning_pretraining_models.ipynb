{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining VerticalGNN Models with solubility dataset\n",
    "\n",
    "1. Pretraining solubility dataset using different dataset sizes and similarity levels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "1. Suggest to skip this notebook and refer to the pre-trained models which were obtained and saved in pretrained_models folder. \n",
    "2. This is because of pytorch reproducibility issue. Despite seeding everything using the seed_everything function in config.py, models trained still report slightly different MSE loss values due to the nondeterministic approach. When compared, weights were different. As such, when pre-training is repeated, there might be a chance that the MSE loss would not be the same and hence results might not be the same as well.\n",
    "3. Since pre-training models provide the initial point for the training, please make use of the pre-trained models available for download from google drive as specified in the README.md\n",
    "4. In the event that you will like to repeat pre-training, to keep things consistent and reproducible, please train the models such that they have the same/similar loss values as the one that was obtained\n",
    "\n",
    "| Data type             | Pretraining Epochs | MSE Loss         |\n",
    "| --------------------- | ------------------ |------------------|\n",
    "| low                   | 20                 |1.031827798485756 |\n",
    "| low                   | 40                 |0.7316062361001968|\n",
    "| low                   | 60                 |0.5605383709073066|\n",
    "| mid                   | 20                 |0.9204714983701706|\n",
    "| mid                   | 40                 |0.6915396004915237|\n",
    "| mid                   | 60                 |0.6143814876675606|\n",
    "| high                  | 20                 |0.7532072991132737|\n",
    "| high                  | 40                 |0.5807877019047737|\n",
    "| high                  | 60                 |0.4340212091803551|\n",
    "| mid (9844)            | 20                 |0.7927087621811109|\n",
    "| mid (9844)            | 40                 |0.5968507482455327|\n",
    "| mid (9984)            | 60                 |0.4210058129750765|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required materials\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "from model import VerticalGNN\n",
    "from config import NUM_FEATURES, NUM_TARGET, EDGE_DIM, DEVICE, SEED_NO, PATIENCE, EPOCHS, NUM_GRAPHS_PER_BATCH, N_SPLITS, best_params_vertical\n",
    "from engine import EngineSol\n",
    "from utils import seed_everything, LoadSolDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training models with 3 different epochs values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_trf_learning_model(train_loader, params, pretrained_model_path, epochs):\n",
    "\n",
    "    '''\n",
    "    Define function to pretrain model with solubililty dataset \n",
    "\n",
    "    Args:\n",
    "    train_loader: DataLoader class from pytorch geometric containing train dataset\n",
    "    params (dict): Dictionary containing hyperparameters\n",
    "    pretrained_model_path (str): path to save the pretrained model\n",
    "    epochs (int): Number of epochs to pretrain the model\n",
    "\n",
    "    Return:\n",
    "    loss: final train loss  \n",
    "    '''\n",
    "\n",
    "    model = VerticalGNN(num_features=NUM_FEATURES, num_targets=NUM_TARGET, num_gin_layers=params['num_gin_layers'], num_graph_trans_layers=params['num_graph_trans_layers'], hidden_size=params['hidden_size'], \n",
    "                        n_heads=params['n_heads'], dropout=params['dropout'], edge_dim=EDGE_DIM)         \n",
    "    model.to(DEVICE)\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr = params['learning_rate'])\n",
    "    eng = EngineSol(model, optimizer, device=DEVICE)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = eng.train(train_loader)\n",
    "        print(f'Epoch: {epoch+1}/{epochs}, train loss : {train_loss}')\n",
    "        print('Saving model...')\n",
    "        torch.save(model.state_dict(), pretrained_model_path)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 4.975466918945313\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 3.526236355304718\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 2.5343623995780944\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 2.088203114271164\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.7970882833003998\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.626753532886505\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.6940837800502777\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 1.6225475907325744\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 1.5674442291259765\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 1.3351163268089294\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 1.331926840543747\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 1.2980240017175675\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 1.2867232590913773\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 1.268978115916252\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 1.2734314918518066\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 1.1626336187124253\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 1.118320208787918\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 1.1530917227268218\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 1.0697223126888276\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 1.031827798485756\n",
      "Saving model...\n",
      "train loss: 1.031827798485756\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_low = LoadSolDataset(root='./data/graph_data/trf_learning_logS_low/', raw_filename='logS_data_for_pretrained_model_low.csv')\n",
    "train_loader_low = DataLoader(train_dataset_low, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/low/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_low, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 4.975458002090454\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 3.5261458277702333\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 2.530808675289154\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 2.076631951332092\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.7774815678596496\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.5944375336170196\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.7354202926158906\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 1.5779489934444428\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 1.608604097366333\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 1.3725912362337112\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 1.3921880573034286\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 1.2886886090040206\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 1.3579948127269745\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 1.2869735389947892\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 1.3152144253253937\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 1.2311797529458999\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 1.1317285686731338\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 1.0764795988798141\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 1.067746415734291\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 1.0582020103931427\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 1.029315599799156\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 1.051555871963501\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 1.031184184551239\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 1.0120239734649659\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.9508287876844406\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.9823512941598892\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.922957056760788\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.8796763300895691\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.8734441727399826\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.8852517634630204\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.8901492863893509\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.8694861739873886\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.8414129614830017\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.8667449742555619\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.8614074319601059\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.7926718354225158\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.8440064415335655\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.8179773271083832\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.7816784664988518\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.7316062361001968\n",
      "Saving model...\n",
      "train loss: 0.7316062361001968\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_low = LoadSolDataset(root='./data/graph_data/trf_learning_logS_low/', raw_filename='logS_data_for_pretrained_model_low.csv')\n",
    "train_loader_low = DataLoader(train_dataset_low, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/low/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_low, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 4.975541830062866\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 3.5287184000015257\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 2.5375942826271056\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 2.0792263388633727\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.7870119392871857\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.6166959881782532\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.7013972103595734\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 1.6047806680202483\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 1.5801450848579406\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 1.3250693202018737\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 1.3415939867496491\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 1.281791526079178\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 1.2789221316576005\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 1.2567991673946382\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 1.2498867332935333\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 1.129315087199211\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 1.0986556440591813\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 1.1065213412046433\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 1.054710328578949\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 1.0256388753652572\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 1.05856596827507\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 1.0664331257343291\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 1.1046979963779449\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 1.0127925038337708\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.9618112653493881\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.9858760744333267\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.9261495232582092\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.8993277251720428\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.8744981169700623\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.8752682834863663\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.8989686727523803\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.8869888544082641\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.8572096586227417\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.8739179253578186\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.8614141434431076\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.7712214022874833\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.847968703508377\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.8151611387729645\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.7812653809785843\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.742865240573883\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.8536667495965957\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.8316302090883255\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.802346932888031\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.7321612924337387\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.713626942038536\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.701488871872425\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.7334756761789322\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.7081797882914543\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.7387452363967896\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.7102971315383911\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.6329196408390999\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.6233999043703079\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.6298085853457451\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.6212661325931549\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.6717091292142868\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.6385776072740554\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.6210744813084602\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.5587680146098137\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.5733458638191223\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.5605383709073066\n",
      "Saving model...\n",
      "train loss: 0.5605383709073066\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_low = LoadSolDataset(root='./data/graph_data/trf_learning_logS_low/', raw_filename='logS_data_for_pretrained_model_low.csv')\n",
    "train_loader_low = DataLoader(train_dataset_low, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/low/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_low, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For mid similarity data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 4.7641252160072325\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 2.62021399140358\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 2.2218790113925935\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 1.7504701912403107\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.5109772205352783\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.521092700958252\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.3634323835372926\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 1.2819459706544876\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 1.2392665475606919\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 1.2077676653862\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 1.177304869890213\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 1.0644060283899308\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 1.1233448326587676\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 1.0770617574453354\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 1.1680368304252624\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 1.1240217685699463\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 1.074212336540222\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 1.039665374159813\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 0.9779352188110352\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 0.9204714983701706\n",
      "Saving model...\n",
      "train loss: 0.9204714983701706\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid/', raw_filename='logS_data_for_pretrained_model_mid.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/mid/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 4.76408360004425\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 2.6200780510902404\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 2.2216820895671843\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 1.7561217367649078\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.5100872576236726\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.527092033624649\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.3475253939628602\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 1.2705524742603302\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 1.234570649266243\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 1.2228021770715714\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 1.2049125552177429\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 1.0559481978416443\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 1.108390074968338\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 1.061267340183258\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 1.1931349098682404\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 1.1377218514680862\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 1.0577419638633727\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 1.0418725073337556\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 0.9791382640600205\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 0.9216494262218475\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 0.9659660249948502\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 0.9273818582296371\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 0.9088931828737259\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 0.964189013838768\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.8882829040288925\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.8681034564971923\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.9437700420618057\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.87576844394207\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.8441860765218735\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.809198260307312\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.8246939569711685\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.8343831643462181\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.7959497094154357\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.7727719724178315\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.7584432810544968\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.750120347738266\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.7291681781411171\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.7300120651721954\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.6826869308948517\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.6915396004915237\n",
      "Saving model...\n",
      "train loss: 0.6915396004915237\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid/', raw_filename='logS_data_for_pretrained_model_mid.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/mid/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 4.764112257957459\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 2.620120829343796\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 2.2216257095336913\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 1.753137969970703\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.514194405078888\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.5218429565429688\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.3437948882579804\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 1.2783657342195511\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 1.239995038509369\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 1.2243042230606078\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 1.17099948823452\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 1.0664605617523193\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 1.1243439316749573\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 1.0530737787485123\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 1.1526587098836898\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 1.1248285621404648\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 1.0609215825796128\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 1.0483556658029556\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 1.0000139325857162\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 0.9269716262817382\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 0.9720607936382294\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 0.9278906345367431\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 0.9316970229148864\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 0.9950145840644836\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.8920726388692856\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.8752586364746093\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.9632259875535965\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.8898848682641983\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.8402166455984116\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.8029685825109482\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.8318449646234513\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.8337487399578094\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.7812608897686004\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.7776463985443115\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.7458174854516983\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.731643658876419\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.7069611430168152\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.7036565035581589\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.6742368251085281\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.6797596752643585\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.6979104682803154\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.7351688891649246\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.6965462535619735\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.6678161963820457\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.7042009323835373\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.6732489183545113\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.6662347480654717\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.6329619064927101\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.6246973276138306\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.6058084219694138\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.6068824395537377\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.6053707987070084\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.6502387404441834\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.5780770033597946\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.5625306352972984\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.5848290905356407\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.5572608679533004\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.5766734659671784\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.6188422188162803\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.6143814876675606\n",
      "Saving model...\n",
      "train loss: 0.6143814876675606\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid/', raw_filename='logS_data_for_pretrained_model_mid.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/mid/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For high similarity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 4.0051886439323425\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 2.299812835454941\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 1.7034678637981415\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 1.4038110733032227\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.2361401051282883\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.2733974426984787\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.1368873178958894\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 1.0297657042741775\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 1.0825812190771102\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 1.0852754890918732\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 0.9220720857381821\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 0.8678085625171661\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 0.8589775294065476\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 0.8817265331745148\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 0.8231119066476822\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 0.8882515132427216\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 0.7919026434421539\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 0.8004891067743302\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 0.8476066261529922\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 0.7532072991132737\n",
      "Saving model...\n",
      "train loss: 0.7532072991132737\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_high = LoadSolDataset(root='./data/graph_data/trf_learning_logS_high/', raw_filename='logS_data_for_pretrained_model_high.csv')\n",
    "train_loader_high = DataLoader(train_dataset_high, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/high/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_high, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 4.00518844127655\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 2.2998244941234587\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 1.7035604417324066\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 1.4074442952871322\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.2380781650543213\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.2788942277431488\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.1270809173583984\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 1.0286381840705872\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 1.0567675799131393\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 1.02924644947052\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 0.8945610582828522\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 0.8767632067203521\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 0.8451282620429993\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 0.8372384369373321\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 0.8079945206642151\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 0.802240577340126\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 0.9301334589719772\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 0.8318765252828598\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 0.8213726669549942\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 0.7428292453289032\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 0.7434953659772873\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 0.7207037746906281\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 0.7105928778648376\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 0.7040786936879158\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.6669160842895507\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.6845797300338745\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.7218208938837052\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.6773011356592178\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.7114861667156219\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.7586345434188843\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.7047036468982697\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.6476821616292\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.6927617818117142\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.6343483328819275\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.6203160628676414\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.6176068648695946\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.5832941755652428\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.5905948564410209\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.61134874522686\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.5807877019047737\n",
      "Saving model...\n",
      "train loss: 0.5807877019047737\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_high = LoadSolDataset(root='./data/graph_data/trf_learning_logS_high/', raw_filename='logS_data_for_pretrained_model_high.csv')\n",
    "train_loader_high = DataLoader(train_dataset_high, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/high/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_high, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 4.005023300647736\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 2.2949384808540345\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 1.6937554836273194\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 1.397811233997345\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.2299401044845581\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.2613649547100068\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.1573308199644088\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 1.0332756817340851\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 1.0800759375095368\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 1.0656437158584595\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 0.9010192543268204\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 0.8724941492080689\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 0.8781602203845977\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 0.8613799124956131\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 0.8102337330579757\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 0.8202665507793426\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 0.943990507721901\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 0.862289446592331\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 0.8533235043287277\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 0.78630411028862\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 0.7534115076065063\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 0.7276884034276009\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 0.716361153125763\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 0.7035256341099739\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.6875345289707184\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.707695472240448\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.7243314504623413\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.6897595584392547\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.7049904480576515\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.7640510052442551\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.7061046689748764\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.6596661448478699\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.698138689994812\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.6528801172971725\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.6349619835615158\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.6108191281557083\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.5930000826716423\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.597012996673584\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.6182617023587227\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.5790361627936363\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.5590772926807404\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.6117000371217728\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.6115259692072869\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.563673534989357\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.5404339596629143\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.5180306032299995\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.5198863714933395\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.5055350750684738\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.5256639048457146\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.5178373858332634\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.5364646360278129\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.48209390193223955\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.4660985469818115\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.49206582903862\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.49718041270971297\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.4597219333052635\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.44230824112892153\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.4640433058142662\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.44664412289857863\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.4340212091803551\n",
      "Saving model...\n",
      "train loss: 0.4340212091803551\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_high = LoadSolDataset(root='./data/graph_data/trf_learning_logS_high/', raw_filename='logS_data_for_pretrained_model_high.csv')\n",
    "train_loader_high = DataLoader(train_dataset_high, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/high/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_high, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For mid similarity, large dataset containing 9844 molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 3.1123597560784755\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 1.8879426687191694\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 1.640125225751828\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 1.4856395171238825\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.3955595921247432\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.2450312956785545\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.152160733174055\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 1.069645412457295\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 1.0502235614336455\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 1.029480978464469\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 1.0057467879393163\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 0.9871399066387079\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 0.9768181015283633\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 0.8989357703771347\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 0.9385771934802716\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 0.8627697229385376\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 0.8983189203800299\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 0.8489820300004421\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 0.8113310436407725\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 0.7927087621811109\n",
      "Saving model...\n",
      "train loss: 0.7927087621811109\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_vertical\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid_10x/', raw_filename='logS_data_for_pretrained_model_mid_10x.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/mid_10x/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 3.11228455335666\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 1.8558634458444057\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 1.6906369083966963\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 1.4936957451013417\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.396361034650069\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.2313241301438747\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.1744323816054907\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 1.077044202731206\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 1.0667632191609113\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 1.0747161782704866\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 1.0136275719373653\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 0.9795814110682561\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 0.9691445246720926\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 0.9169595623627688\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 0.928740510573754\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 0.859115019822732\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 0.8944688439369202\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 0.8571292696855007\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 0.8142270705638788\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 0.798192099118844\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 0.8070147572419583\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 0.8023783839665927\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 0.7756786331152304\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 0.8163695457654122\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.7611839771270752\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.7508067091306051\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.7691753644209641\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.7222989881649996\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.7081706890693078\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.6980205529775375\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.6932738362214504\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.6984686056772867\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.6983529734305847\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.6517826280532739\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.6313591859279535\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.6354254201436654\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.6152510665930234\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.599138855169981\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.6145761907100677\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.5968507482455327\n",
      "Saving model...\n",
      "train loss: 0.5968507482455327\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_vertical\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid_10x/', raw_filename='logS_data_for_pretrained_model_mid_10x.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/mid_10x/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 3.1122490075918345\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 1.8636333086551764\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 1.6833096177150042\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 1.497954215758886\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.430017718902001\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.2342187273196685\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.186734751248971\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 1.0787757803232243\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 1.0612002045680315\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 1.071259931111947\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 1.0202723879080553\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 0.9880763811942859\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 0.9794013500213623\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 0.9162734487117865\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 0.9443113895562979\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 0.8879111149372199\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 0.8774954936443231\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 0.8614643628780658\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 0.8219651381174723\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 0.7980728584986466\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 0.8166612944541833\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 0.7913270898354359\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 0.7613034554016895\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 0.8287195823131464\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.7497933461115911\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.7443978274479891\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.7594816165092664\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.7248390576778314\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.7306030965768374\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.7096469562787276\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.7145444047756684\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.6906129458011725\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.6991201539834341\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.6520394018063178\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.6452513703933129\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.6379210987152197\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.632593049452855\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.6034920093340751\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.6214970174508218\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.572501540184021\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.5980172554651896\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.5771067562775735\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.5674473857268308\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.5488755297966492\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.6126757355836722\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.5298564265935849\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.5188749998043745\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.51333109384928\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.50735364204798\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.5471274837469443\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.5152993079943534\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.49380425688547963\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.49560252061256993\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.49515937383358294\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.44231903782257664\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.45980231578533465\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.4422484659231626\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.4196953269151541\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.44950714325293517\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.42100581297507655\n",
      "Saving model...\n",
      "train loss: 0.42100581297507655\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_vertical\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid_10x/', raw_filename='logS_data_for_pretrained_model_mid_10x.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/vertical/mid_10x/pretrained_vertical_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adba4fb230ed7dc63d790cdaaae75000cb531237ea070291c76da314f993704f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

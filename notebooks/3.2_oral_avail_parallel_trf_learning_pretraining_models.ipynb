{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretraining ParallelGNN Models with solubility dataset\n",
    "\n",
    "1. Pretraining solubility dataset using different dataset sizes and similarity levels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note:\n",
    "1. Suggest to skip this notebook and refer to the pre-trained models which were obtained and saved in pretrained_models folder. \n",
    "2. This is because of pytorch reproducibility issue. Despite seeding everything using the seed_everything function in config.py, models trained still report slightly different MSE loss values due to the nondeterministic approach. When compared, weights were different. As such, when pre-training is repeated, there might be a chance that the MSE loss would not be the same and hence results might not be the same as well.\n",
    "3. Since pre-training models provide the initial point for the training, please make use of the pre-trained models that were obtained and uploaded to GitHub for reproducibility of results obtained.\n",
    "4. In the event that you will like to repeat pre-training, to keep things consistent and reproducible, please train the models such that they have the same/similar loss values as the one that was obtained\n",
    "\n",
    "| Data type             | Pretraining Epochs | MSE Loss         |\n",
    "| --------------------- | ------------------ |------------------|\n",
    "| low                   | 20                 |0.9308284640312194|\n",
    "| low                   | 40                 |0.7136518269777298|\n",
    "| low                   | 60                 |0.5759974002838135|\n",
    "| mid                   | 20                 |0.8083086103200913|\n",
    "| mid                   | 40                 |0.5740450233221054|\n",
    "| mid                   | 60                 |0.4558365240693092|\n",
    "| high                  | 20                 |0.7509024858474731|\n",
    "| high                  | 40                 |0.5216782301664352|\n",
    "| high                  | 60                 |0.4045856937766075|\n",
    "| mid (9844)            | 20                 |0.755623785349039 |\n",
    "| mid (9844)            | 40                 |0.5991875949578408|\n",
    "| mid (9984)            | 60                 |0.4397607071277423|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required materials\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "\n",
    "from model import ParallelGNN\n",
    "from config import NUM_FEATURES, NUM_TARGET, EDGE_DIM, DEVICE, SEED_NO, PATIENCE, EPOCHS, NUM_GRAPHS_PER_BATCH, N_SPLITS, best_params_parallel\n",
    "from engine import EngineSol, EngineHOB\n",
    "from utils import seed_everything, LoadHOBDataset, LoadSolDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-training models with 3 different epochs values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_trf_learning_model(train_loader, params, pretrained_model_path, epochs):\n",
    "\n",
    "    '''\n",
    "    Define function to pretrain model with solubililty dataset \n",
    "\n",
    "    Args:\n",
    "    train_loader: DataLoader class from pytorch geometric containing train dataset\n",
    "    params (dict): Dictionary containing hyperparameters\n",
    "    pretrained_model_path (str): path to save the pretrained model\n",
    "    epochs (int): Number of epochs to pretrain the model\n",
    "\n",
    "    Return:\n",
    "    loss: final train loss  \n",
    "    '''\n",
    "\n",
    "    model = ParallelGNN(num_features=NUM_FEATURES, num_targets=NUM_TARGET, num_gin_layers=params['num_gin_layers'], num_graph_trans_layers=params['num_graph_trans_layers'], hidden_size=params['hidden_size'], \n",
    "                        n_heads=params['n_heads'], dropout=params['dropout'], edge_dim=EDGE_DIM)         \n",
    "    model.to(DEVICE)\n",
    "    optimizer=torch.optim.Adam(model.parameters(),lr = params['learning_rate'])\n",
    "    eng = EngineSol(model, optimizer, device=DEVICE)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = eng.train(train_loader)\n",
    "        print(f'Epoch: {epoch+1}/{epochs}, train loss : {train_loss}')\n",
    "        print('Saving model...')\n",
    "        torch.save(model.state_dict(), pretrained_model_path)\n",
    "\n",
    "    return train_loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow to pretrain models\n",
    "1. seed_everything with a seed no of 0. SEED_NO available from the config.py file\n",
    "2. load in dataset. Root path of the dataset and raw file name of the dataset is required. root path --> must contain 2 folders, raw and processed. raw csv file will be kept in the raw folder\n",
    "3. first run will include the conversion of smiles to graph data --> take about 1 min to be done. Subsequent run will just load from what was already loaded previously\n",
    "4. model will then be pre-trained and saved into the path listed "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For low similarity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 5.5211021900177\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 3.141400396823883\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 2.2217857837677\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 1.924638706445694\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.621340012550354\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.4470352351665496\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.502454122900963\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 1.2814750909805297\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 1.2383556008338927\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 1.2024710565805434\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 1.0959697127342225\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 1.0768183469772339\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 1.0273351699113846\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 1.181999284029007\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 1.0718557298183442\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 0.9875313371419907\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 1.0326415598392487\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 0.9551603615283966\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 0.8969757437705994\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 0.9308284640312194\n",
      "Saving model...\n",
      "train loss: 0.9308284640312194\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_parallel\n",
    "\n",
    "# Seed everything to ensure reproducibility. SEED_NO = 0 available in the config.py file \n",
    "seed_everything(SEED_NO)\n",
    "\n",
    "# load solubility dataset. root --> root path of the data, raw filename --> name of raw file \n",
    "train_dataset_low = LoadSolDataset(root='./data/graph_data/trf_learning_logS_low/', raw_filename='logS_data_for_pretrained_model_low.csv')\n",
    "train_loader_low = DataLoader(train_dataset_low, batch_size=NUM_GRAPHS_PER_BATCH, shuffle=True)\n",
    "\n",
    "# path to save the pre-trained models\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/low/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "# train the mode\n",
    "train_loss = run_training_trf_learning_model(train_loader_low, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 5.521102237701416\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 3.141400468349457\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 2.2217830300331114\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 1.9249813914299012\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.621603113412857\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.4567142754793168\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.5298889398574829\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 1.3079859733581543\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 1.205931144952774\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 1.2682111114263535\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 1.135237944126129\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 1.1480298429727553\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 1.0344093769788743\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 1.2882357776165008\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 1.100435796380043\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 1.0175404638051986\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 1.0213215470314025\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 0.97593834400177\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 0.8843822956085206\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 0.9210713595151901\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 0.8976391285657883\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 0.8967855513095856\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 0.9203633427619934\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 0.9344701856374741\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.8324097901582718\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.8402212917804718\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.7932073324918747\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.7784348741173744\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.8128478676080704\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.7268701255321502\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.7665499746799469\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.746751680970192\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.736331331729889\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.7228858739137649\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.7312944889068603\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.8587132453918457\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.7710440337657929\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.7212365061044693\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.7004661127924919\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.7136518269777298\n",
      "Saving model...\n",
      "train loss: 0.7136518269777298\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_parallel\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_low = LoadSolDataset(root='./data/graph_data/trf_learning_logS_low/', raw_filename='logS_data_for_pretrained_model_low.csv')\n",
    "train_loader_low = DataLoader(train_dataset_low, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/low/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "train_loss = run_training_trf_learning_model(train_loader_low, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 5.521102249622345\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 3.141400420665741\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 2.2217946290969848\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 1.9249893367290496\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.6205761551856994\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.4505530506372453\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.4902881979942322\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 1.2721269994974136\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 1.2233723133802414\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 1.214267760515213\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 1.0968627721071242\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 1.082870602607727\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 1.0158810049295426\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 1.1936377555131912\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 1.0723388195037842\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 0.9731283366680146\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 1.0047398179769516\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 0.9324871450662613\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 0.8868649542331696\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 0.9240643113851548\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 0.9383889317512513\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 0.87709039747715\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 0.8944298416376114\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 1.0342541486024857\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.8494367182254792\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.8435739278793335\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.8068864136934281\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.7756067186594009\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.7991362690925599\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.7388932764530182\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.7722811788320542\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.73411013931036\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.7342328935861587\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.7226315408945083\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.7319655895233155\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.8539615899324418\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.7706894904375077\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.7148233383893967\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.6887738898396492\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.6956726789474488\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.7145314067602158\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.6593817681074142\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.6467006668448448\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.6727548465132713\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.646480830013752\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.6702676400542259\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.6607783243060112\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.5737392351031303\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.6154762089252472\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.6634342089295387\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.6839971080422401\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.6216988086700439\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.5598670721054078\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.5444081842899322\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.5793839633464813\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.5260212391614913\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.52465590685606\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.5189240202307701\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.5993412107229232\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.5759974002838135\n",
      "Saving model...\n",
      "train loss: 0.5759974002838135\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_low = LoadSolDataset(root='./data/graph_data/trf_learning_logS_low/', raw_filename='logS_data_for_pretrained_model_low.csv')\n",
    "train_loader_low = DataLoader(train_dataset_low, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/low/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "train_loss = run_training_trf_learning_model(train_loader_low, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For mid similarity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 4.544011640548706\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 2.318880182504654\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 1.9137514233589172\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 1.4855545341968537\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.470324409008026\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.3583060413599015\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.328382682800293\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 1.1010364681482314\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 1.0257614970207214\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 0.9629837214946747\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 1.028915172815323\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 0.8849341839551925\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 0.9177361816167832\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 0.8962326943874359\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 0.8262790441513062\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 0.8209617614746094\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 0.8114768356084824\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 0.7693413972854615\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 0.8109969437122345\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 0.8083086103200913\n",
      "Saving model...\n",
      "train loss: 0.8083086103200913\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid/', raw_filename='logS_data_for_pretrained_model_mid.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/mid/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 4.544017827510833\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 2.3186146318912506\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 1.9133813500404357\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 1.4853240251541138\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.4832194328308106\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.4374340355396271\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.5273986399173736\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 1.1304687559604645\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 1.0523628145456314\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 1.0102443516254425\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 0.9693474620580673\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 0.8983599960803985\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 0.9268206745386124\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 0.8757076412439346\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 0.8673748910427094\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 0.816517812013626\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 0.8133540689945221\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 0.7676092058420181\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 0.8048804610967636\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 0.7994141489267349\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 0.7543747499585152\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 0.7125449895858764\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 0.7161221742630005\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 0.7485067635774613\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.6924335211515427\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.7179932117462158\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.6991476714611053\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.7477731108665466\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.7355256348848342\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.7000614136457444\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.6397955372929574\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.7256136149168014\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.6433489471673965\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.749222731590271\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.6345584586262702\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.6319656014442444\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.6227072238922119\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.6192490428686142\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.629846727848053\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.5740450233221054\n",
      "Saving model...\n",
      "train loss: 0.5740450233221054\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid/', raw_filename='logS_data_for_pretrained_model_mid.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/mid/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 4.544017779827118\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 2.3186147034168245\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 1.9133814930915833\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 1.4853241264820098\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.4832176327705384\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.4374283611774445\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.5273414522409439\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 1.130295193195343\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 1.0499890804290772\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 1.0120443105697632\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 0.9729029893875122\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 0.8972269594669342\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 0.9287420600652695\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 0.8851360738277435\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 0.8213381260633469\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 0.8382677048444748\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 0.8254083186388016\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 0.781164237856865\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 0.8421979874372483\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 0.78559740036726\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 0.7606045439839363\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 0.7228606969118119\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 0.7351211965084076\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 0.8126411676406861\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.7035202205181121\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.7199805974960327\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.6857096299529075\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.7660354614257813\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.6874712079763412\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.71977758705616\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.6857195541262626\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.7971987366676331\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.7007717072963715\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.7390681117773056\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.6312673717737198\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.6044558420777321\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.6123717412352562\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.6008885607123375\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.6314792484045029\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.5849637016654015\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.5703858092427254\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.5568558648228645\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.6252515524625778\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.5825273811817169\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.6173606291413307\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.6132584929466247\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.5559619933366775\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.5333452478051186\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.5334618151187897\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.5289438858628273\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.5043528199195861\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.5000837832689286\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.5573047384619713\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.5010497108101845\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.47904388010501864\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.4873178943991661\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.4521643102169037\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.45803956091403963\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.459557743370533\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.45583652406930925\n",
      "Saving model...\n",
      "train loss: 0.45583652406930925\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid/', raw_filename='logS_data_for_pretrained_model_mid.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/mid/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For high similarity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 4.642562830448151\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 2.101711893081665\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 1.7573925614356996\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 1.3711799442768098\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.2677027255296707\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.1138039022684096\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.124337151646614\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 0.9639853119850159\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 0.9671495497226715\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 0.9340693712234497\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 0.8093831866979599\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 0.8000556081533432\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 0.7660887330770493\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 0.7237061128020287\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 0.720808693766594\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 0.7477890074253082\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 0.8619926393032074\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 0.8179649114608765\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 0.7814394533634186\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 0.7509024858474731\n",
      "Saving model...\n",
      "train loss: 0.7509024858474731\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_parallel\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_high = LoadSolDataset(root='./data/graph_data/trf_learning_logS_high/', raw_filename='logS_data_for_pretrained_model_high.csv')\n",
    "train_loader_high = DataLoader(train_dataset_high, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/high/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_high, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 4.642562794685364\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 2.1017646968364714\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 1.757392978668213\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 1.3698823034763337\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.2634358733892441\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.1285671651363374\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.1352617740631104\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 0.9667869120836258\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 0.974018257856369\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 0.9377013027668\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 0.8118010640144349\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 0.8056966811418533\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 0.7730775952339173\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 0.7298048958182335\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 0.7278229787945747\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 0.7500758439302444\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 0.8736153990030289\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 0.8371679902076721\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 0.766717629134655\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 0.7418757528066635\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 0.685748566687107\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 0.7008645415306092\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 0.6785455480217933\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 0.6449000552296639\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.6247257888317108\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.6925567537546158\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.6165714621543884\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.6044965609908104\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.5898977130651474\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.5808922931551933\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.577995391190052\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.5806103974580765\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.589673464000225\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.5433876976370812\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.5223310828208924\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.5343440905213356\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.572662490606308\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.6235401287674904\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.5068932622671127\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.5216782301664352\n",
      "Saving model...\n",
      "train loss: 0.5216782301664352\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_high = LoadSolDataset(root='./data/graph_data/trf_learning_logS_high/', raw_filename='logS_data_for_pretrained_model_high.csv')\n",
    "train_loader_high = DataLoader(train_dataset_high, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/high/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_high, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 4.642562878131867\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 2.1017118632793426\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 1.757395625114441\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 1.3700670182704926\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.2635839074850082\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.1241948574781417\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.1259318739175797\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 0.9613223910331726\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 0.9676713794469833\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 0.9594990938901902\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 0.8161195397377015\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 0.8084379732608795\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 0.7736717820167541\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 0.7311766460537911\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 0.7311332583427429\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 0.7419393539428711\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 0.8564288049936295\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 0.8260910242795945\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 0.7838227540254593\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 0.7580062836408615\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 0.6877608448266983\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 0.6993257820606231\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 0.6837797999382019\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 0.647973844408989\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.6238513603806496\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.6887319654226303\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.615309551358223\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.6135646343231201\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.5941611617803574\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.5737517803907395\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.5801912277936936\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.5975957453250885\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.5821314051747322\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.5397813767194748\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.522156135737896\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.5268900200724602\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.5671114534139633\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.6148287340998649\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.5064444720745087\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.5079329058527946\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.5181217476725578\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.5016527563333512\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.49402921348810197\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.5395604729652405\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.5472146645188332\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.5177407130599022\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.4909663662314415\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.4873215973377228\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.441621196269989\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.44119514226913453\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.4485104411840439\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.46429392099380495\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.5030656918883324\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.4337085038423538\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.4585315898060799\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.4494811832904816\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.4413169786334038\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.4614449813961983\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.44537678062915803\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.4045856937766075\n",
      "Saving model...\n",
      "train loss: 0.4045856937766075\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_high = LoadSolDataset(root='./data/graph_data/trf_learning_logS_high/', raw_filename='logS_data_for_pretrained_model_high.csv')\n",
    "train_loader_high = DataLoader(train_dataset_high, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/high/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_high, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For mid similarity dataset of 9844 molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, train loss : 4.002060560079721\n",
      "Saving model...\n",
      "Epoch: 2/20, train loss : 1.8875243541521904\n",
      "Saving model...\n",
      "Epoch: 3/20, train loss : 1.5322926869759192\n",
      "Saving model...\n",
      "Epoch: 4/20, train loss : 1.2759567407461314\n",
      "Saving model...\n",
      "Epoch: 5/20, train loss : 1.1960181410496051\n",
      "Saving model...\n",
      "Epoch: 6/20, train loss : 1.1422757231272185\n",
      "Saving model...\n",
      "Epoch: 7/20, train loss : 1.1556563973426819\n",
      "Saving model...\n",
      "Epoch: 8/20, train loss : 1.0475460779972565\n",
      "Saving model...\n",
      "Epoch: 9/20, train loss : 0.971838096777598\n",
      "Saving model...\n",
      "Epoch: 10/20, train loss : 0.9097124399282993\n",
      "Saving model...\n",
      "Epoch: 11/20, train loss : 0.9119785932394174\n",
      "Saving model...\n",
      "Epoch: 12/20, train loss : 0.8857069856081253\n",
      "Saving model...\n",
      "Epoch: 13/20, train loss : 0.8691081985449179\n",
      "Saving model...\n",
      "Epoch: 14/20, train loss : 0.8624108678255326\n",
      "Saving model...\n",
      "Epoch: 15/20, train loss : 0.8587329143132919\n",
      "Saving model...\n",
      "Epoch: 16/20, train loss : 0.8370941846798627\n",
      "Saving model...\n",
      "Epoch: 17/20, train loss : 0.8068988445477608\n",
      "Saving model...\n",
      "Epoch: 18/20, train loss : 0.8549055793346503\n",
      "Saving model...\n",
      "Epoch: 19/20, train loss : 0.7809014457922715\n",
      "Saving model...\n",
      "Epoch: 20/20, train loss : 0.755623785349039\n",
      "Saving model...\n",
      "train loss: 0.755623785349039\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "params = best_params_parallel\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid_10x/', raw_filename='logS_data_for_pretrained_model_mid_10x.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/mid_10x/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/40, train loss : 4.002092294203929\n",
      "Saving model...\n",
      "Epoch: 2/40, train loss : 1.8872488400874994\n",
      "Saving model...\n",
      "Epoch: 3/40, train loss : 1.5029107760160396\n",
      "Saving model...\n",
      "Epoch: 4/40, train loss : 1.267299500795511\n",
      "Saving model...\n",
      "Epoch: 5/40, train loss : 1.1722230651439765\n",
      "Saving model...\n",
      "Epoch: 6/40, train loss : 1.1312551956910353\n",
      "Saving model...\n",
      "Epoch: 7/40, train loss : 1.0996684554295661\n",
      "Saving model...\n",
      "Epoch: 8/40, train loss : 1.0234598227036305\n",
      "Saving model...\n",
      "Epoch: 9/40, train loss : 0.9531340033580096\n",
      "Saving model...\n",
      "Epoch: 10/40, train loss : 0.9272402708347027\n",
      "Saving model...\n",
      "Epoch: 11/40, train loss : 0.9092136957706549\n",
      "Saving model...\n",
      "Epoch: 12/40, train loss : 0.9016431692319039\n",
      "Saving model...\n",
      "Epoch: 13/40, train loss : 0.8663428548054818\n",
      "Saving model...\n",
      "Epoch: 14/40, train loss : 0.8376778685129606\n",
      "Saving model...\n",
      "Epoch: 15/40, train loss : 0.842821403955802\n",
      "Saving model...\n",
      "Epoch: 16/40, train loss : 0.8413187158413422\n",
      "Saving model...\n",
      "Epoch: 17/40, train loss : 0.7867122552333734\n",
      "Saving model...\n",
      "Epoch: 18/40, train loss : 0.8537968397140503\n",
      "Saving model...\n",
      "Epoch: 19/40, train loss : 0.777014611623226\n",
      "Saving model...\n",
      "Epoch: 20/40, train loss : 0.7537700090652857\n",
      "Saving model...\n",
      "Epoch: 21/40, train loss : 0.7356914159579154\n",
      "Saving model...\n",
      "Epoch: 22/40, train loss : 0.7222426281525538\n",
      "Saving model...\n",
      "Epoch: 23/40, train loss : 0.7447198698153863\n",
      "Saving model...\n",
      "Epoch: 24/40, train loss : 0.8042103770451668\n",
      "Saving model...\n",
      "Epoch: 25/40, train loss : 0.6915347606707842\n",
      "Saving model...\n",
      "Epoch: 26/40, train loss : 0.6824634671211243\n",
      "Saving model...\n",
      "Epoch: 27/40, train loss : 0.7024987569222083\n",
      "Saving model...\n",
      "Epoch: 28/40, train loss : 0.6562869441814911\n",
      "Saving model...\n",
      "Epoch: 29/40, train loss : 0.6688517186886225\n",
      "Saving model...\n",
      "Epoch: 30/40, train loss : 0.6411110598307389\n",
      "Saving model...\n",
      "Epoch: 31/40, train loss : 0.6460950466302725\n",
      "Saving model...\n",
      "Epoch: 32/40, train loss : 0.6423640908339084\n",
      "Saving model...\n",
      "Epoch: 33/40, train loss : 0.6277148158122332\n",
      "Saving model...\n",
      "Epoch: 34/40, train loss : 0.625462246246827\n",
      "Saving model...\n",
      "Epoch: 35/40, train loss : 0.5867292353740106\n",
      "Saving model...\n",
      "Epoch: 36/40, train loss : 0.6003110462274307\n",
      "Saving model...\n",
      "Epoch: 37/40, train loss : 0.594458961333984\n",
      "Saving model...\n",
      "Epoch: 38/40, train loss : 0.6085553329724532\n",
      "Saving model...\n",
      "Epoch: 39/40, train loss : 0.6218372079042288\n",
      "Saving model...\n",
      "Epoch: 40/40, train loss : 0.5991875949578408\n",
      "Saving model...\n",
      "train loss: 0.5991875949578408\n"
     ]
    }
   ],
   "source": [
    "epochs = 40\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid_10x/', raw_filename='logS_data_for_pretrained_model_mid_10x.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/mid_10x/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/60, train loss : 4.002092129144913\n",
      "Saving model...\n",
      "Epoch: 2/60, train loss : 1.8852795607004411\n",
      "Saving model...\n",
      "Epoch: 3/60, train loss : 1.5093652590727196\n",
      "Saving model...\n",
      "Epoch: 4/60, train loss : 1.2645879005774474\n",
      "Saving model...\n",
      "Epoch: 5/60, train loss : 1.1910986640514472\n",
      "Saving model...\n",
      "Epoch: 6/60, train loss : 1.111995279788971\n",
      "Saving model...\n",
      "Epoch: 7/60, train loss : 1.014367821889046\n",
      "Saving model...\n",
      "Epoch: 8/60, train loss : 0.9900711392744993\n",
      "Saving model...\n",
      "Epoch: 9/60, train loss : 0.9730033324314997\n",
      "Saving model...\n",
      "Epoch: 10/60, train loss : 0.9239229605748103\n",
      "Saving model...\n",
      "Epoch: 11/60, train loss : 0.9563158123921125\n",
      "Saving model...\n",
      "Epoch: 12/60, train loss : 0.8749214685880221\n",
      "Saving model...\n",
      "Epoch: 13/60, train loss : 0.8673534859449435\n",
      "Saving model...\n",
      "Epoch: 14/60, train loss : 0.8366829875187997\n",
      "Saving model...\n",
      "Epoch: 15/60, train loss : 0.832387795815101\n",
      "Saving model...\n",
      "Epoch: 16/60, train loss : 0.8526300207162515\n",
      "Saving model...\n",
      "Epoch: 17/60, train loss : 0.7804224735651261\n",
      "Saving model...\n",
      "Epoch: 18/60, train loss : 0.8343605185166384\n",
      "Saving model...\n",
      "Epoch: 19/60, train loss : 0.7740642573588934\n",
      "Saving model...\n",
      "Epoch: 20/60, train loss : 0.740961478306697\n",
      "Saving model...\n",
      "Epoch: 21/60, train loss : 0.7320829927921295\n",
      "Saving model...\n",
      "Epoch: 22/60, train loss : 0.7281484252367264\n",
      "Saving model...\n",
      "Epoch: 23/60, train loss : 0.7123438715934753\n",
      "Saving model...\n",
      "Epoch: 24/60, train loss : 0.7283301597986466\n",
      "Saving model...\n",
      "Epoch: 25/60, train loss : 0.6853874822457632\n",
      "Saving model...\n",
      "Epoch: 26/60, train loss : 0.6725432521257645\n",
      "Saving model...\n",
      "Epoch: 27/60, train loss : 0.7099925585282154\n",
      "Saving model...\n",
      "Epoch: 28/60, train loss : 0.6509014352774009\n",
      "Saving model...\n",
      "Epoch: 29/60, train loss : 0.6668650920574481\n",
      "Saving model...\n",
      "Epoch: 30/60, train loss : 0.6440821626247504\n",
      "Saving model...\n",
      "Epoch: 31/60, train loss : 0.6249665121237437\n",
      "Saving model...\n",
      "Epoch: 32/60, train loss : 0.6448070674370496\n",
      "Saving model...\n",
      "Epoch: 33/60, train loss : 0.6026467963671073\n",
      "Saving model...\n",
      "Epoch: 34/60, train loss : 0.5977250459866646\n",
      "Saving model...\n",
      "Epoch: 35/60, train loss : 0.574303652995672\n",
      "Saving model...\n",
      "Epoch: 36/60, train loss : 0.581922282011081\n",
      "Saving model...\n",
      "Epoch: 37/60, train loss : 0.5756482825829432\n",
      "Saving model...\n",
      "Epoch: 38/60, train loss : 0.5706101411428207\n",
      "Saving model...\n",
      "Epoch: 39/60, train loss : 0.6528560366386023\n",
      "Saving model...\n",
      "Epoch: 40/60, train loss : 0.6185887226691613\n",
      "Saving model...\n",
      "Epoch: 41/60, train loss : 0.5654839751047965\n",
      "Saving model...\n",
      "Epoch: 42/60, train loss : 0.5347209863173656\n",
      "Saving model...\n",
      "Epoch: 43/60, train loss : 0.5817456635145041\n",
      "Saving model...\n",
      "Epoch: 44/60, train loss : 0.5347076043104514\n",
      "Saving model...\n",
      "Epoch: 45/60, train loss : 0.534146982889909\n",
      "Saving model...\n",
      "Epoch: 46/60, train loss : 0.526336119725154\n",
      "Saving model...\n",
      "Epoch: 47/60, train loss : 0.5108791765494224\n",
      "Saving model...\n",
      "Epoch: 48/60, train loss : 0.49013431714131284\n",
      "Saving model...\n",
      "Epoch: 49/60, train loss : 0.509312860476665\n",
      "Saving model...\n",
      "Epoch: 50/60, train loss : 0.527969342775834\n",
      "Saving model...\n",
      "Epoch: 51/60, train loss : 0.49859448350392854\n",
      "Saving model...\n",
      "Epoch: 52/60, train loss : 0.516900129807301\n",
      "Saving model...\n",
      "Epoch: 53/60, train loss : 0.4977645109861325\n",
      "Saving model...\n",
      "Epoch: 54/60, train loss : 0.4844145537951054\n",
      "Saving model...\n",
      "Epoch: 55/60, train loss : 0.4796655193353311\n",
      "Saving model...\n",
      "Epoch: 56/60, train loss : 0.5091820527345706\n",
      "Saving model...\n",
      "Epoch: 57/60, train loss : 0.4937219474560175\n",
      "Saving model...\n",
      "Epoch: 58/60, train loss : 0.4448032081127167\n",
      "Saving model...\n",
      "Epoch: 59/60, train loss : 0.47101532572355026\n",
      "Saving model...\n",
      "Epoch: 60/60, train loss : 0.4397607071277423\n",
      "Saving model...\n",
      "train loss: 0.4397607071277423\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "params = best_params_parallel\n",
    "\n",
    "\n",
    "seed_everything(SEED_NO)\n",
    "train_dataset_mid = LoadSolDataset(root='./data/graph_data/trf_learning_logS_mid_10x/', raw_filename='logS_data_for_pretrained_model_mid_10x.csv')\n",
    "train_loader_mid = DataLoader(train_dataset_mid, batch_size=256, shuffle=True)\n",
    "pretrained_model_path = f'./trf_learning_models/pretrained_models/parallel/mid_10x/pretrained_parallel_model_{epochs}_epoch.pt'\n",
    "\n",
    "train_loss = run_training_trf_learning_model(train_loader_mid, params, pretrained_model_path, epochs)\n",
    "print(f'train loss: {train_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "adba4fb230ed7dc63d790cdaaae75000cb531237ea070291c76da314f993704f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
